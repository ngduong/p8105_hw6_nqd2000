---
title: "P8105 -- Homework 6"
author: "Ngoc Duong - nqd2000"
date: "11/23/2019"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(readr)
library(tidyverse)
library(modelr)
library(mgcv)
library(corrplot)
library(car)
library(patchwork)
```

### Problem 1
```{r}
bw_data = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(babysex = factor(babysex),
         frace = factor(frace),
         malform = factor(malform),
         mrace = factor(mrace)) %>% 
  select(pnumlbw, pnumsga, parity, bwt,everything())

sum(is.na(bw_data))
```

I used `str(bw_data)` to check the data type of each variable, and `summary(bw_data)` to check if there's any outliers and NA's. Summary statistics suggested there didn't seem to be any NA's (another quick way to check NA's could be `sum(is.na(bw_data))` = `r sum(is.na(bw_data))` which gave the same conclusion). Additionally, since `pnumsga`, `pnumlbw`, and `parity` values are always 0, they probably won't contribute to the model and thus I'll leave them out when building regression models (by selecting only subset of `bw_data` without them).

Now I try to propose a regression model with birth weight as the outcome variable

```{r}
#make a correlation plot to look at the relationship between the independent and dependent variables
bw_data[,4:20] %>%
Filter(is.numeric,.) %>% 
  cor() %>%   
  corrplot(method = "circle", type = "upper", diag=FALSE)
```
Variables that `bwt` appears to be moderately and highly correlated with include: `bhead`, `blength`, `gaweeks`, and `delwt`, while `deltwt` also appears to be correlated with `ppbmi` and `ppwt` (which are also highly correlated as they were both constructed based on mother's pre-pregnancy weight). Other than that, `bheard` and `blength` are correlated because they both reflect the size of the infants (in different aspects).

Therefore, from what I've seen above, some of the variables I want to include are `bhead`, `blength`, `gaweeks`, `delwt`, and `ppbmi` (since `ppbmi` and `ppwt` are highly correlated, including both might cause the problem of multicollinearity, so I picked `ppwt` (since it seems to be a little more associated with infant's weight). Other categorical variables not covered by the correlation plot that I think (through appropriate reasoning) are related to the outcome variable are: `babysex` and mother's race `mrace` (or `frace`). 

```{r}
bw_fit_base = lm(bwt ~ bhead + blength + gaweeks + delwt + ppbmi + mrace + babysex, 
                 data = bw_data) 
bw_fit_base %>% 
  broom::glance() %>% 
  .[,1:2]
```
This model has an adjusted r-squared of 71.2%, which seems decent. 

We should probably also check for multicollinearity (for interpretation purpose, although this wouldn't affect R-squared value)
```{r}
vif(bw_fit_base)
```
No VIF values were above 5, so we don't need to worry about multicollinearity problem. 

We can also attempt to use stepwise regression to come up with a model based on BIC criterion
```{r, include = FALSE}
#using stepwise regression (backward)
mult.fit = lm(bwt ~ ., data=bw_data)
step(mult.fit, 
     direction='backward', 
     criterion = "BIC", 
     k=log(length(bw_data)))
```

```{r}
#This is the final model suggested by backward stepwise regression
reg_bic = lm(formula = bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + mrace + ppwt + smoken, data = bw_data)
```

```{r}
#obtain necessary statistics for this model
reg_bic %>% 
  broom::glance() %>% 
  .[,1:2]
```
Adjusted r-squared obtained from this model is 71.7%, which is slight better than the previously proposed model. 

Checking for multicollinearity: 
```{r}
vif(reg_bic)
```
No values were greater than 5, so we don't need to worry about multicollinearity issue. 

We can also see that the original proposed model happens to be nested within this model (as suggested by stepwise regression), we can use partial F-test to test which model is "superior".

```{r}
anova(bw_fit_base, reg_bic)
```

Since the p-value reported by the partial F-test is very small (<2.2e-16), we can conclude that model 2 (expanded model suggested by stepwise regression) is "superior".

Check model assumption (normality of residuals) by plotting resid vs. fitted values
```{r}
bw_data %>% 
  add_residuals(reg_bic) %>%                   # adding residuals to our df
  add_predictions(reg_bic) %>%                 # add predictions using our df
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3, color = "darkgreen") +
  geom_smooth(method = "lm", color = "purple") +
  labs(title = "Scatterplot of residuals vs. fitted values",
       x = "Estimated birth weight (g)",
       y = "Residuals") + 
  theme(plot.title =     
          element_text(hjust = 0.5, size=12, face='bold'))
```

After that, we run the two models suggested by the problem:
```{r}
#using length at birth and gestational age as predictors (main effects only)
fit_main = lm(bwt ~ blength + gaweeks, data = bw_data) 
fit_main %>% 
  broom::glance()
```

```{r}
#using head circumference, length, sex, and all interactions (including the three-way interaction) between these
fit_int = lm(bwt ~ bhead*blength*babysex, data = bw_data)
fit_int %>% 
  broom::glance()
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

### Problem 2

```{r}
#Download the data 
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = dplyr::recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
#function returns needed values 
mystats = function(lm){
  mystats = cbind(
  lm %>% 
    broom::glance() %>% 
  .[,1],
  lm %>% 
  broom::tidy() %>% 
  select(term, estimate) %>% 
  pivot_wider(.,
              names_from = term, 
              values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log_beta_prod = log(intercept * tmin, base = exp(1))) %>% 
  .[,3])
 mystats
}
```

Obtain bootstraps
```{r}
set.seed(7)
# use R built in function modelr to obtain results and plot estimates
weather_stats = 
  weather_df %>% 
  modelr::bootstrap(n = 100) %>% 
  mutate(models = 
           map(strap, ~lm(tmax ~ tmin, data = .x)),
         results = 
           map(models, mystats)) %>% 
  select(-strap,-models) %>% 
  unnest(results)

#start to plot R-squared 
weather_stats %>% 
  ggplot(aes(x = r.squared, 
             fill = "#0000ff", 
             color = "#0000ff")) +                  #plot R-squared's
  geom_density(alpha = 0.3) +
  labs(title = "Density plot of estimated R-squared across 5000 straps",
       y = "Density (%)",
       x = "R-squared") +                           #add graph and axis title
  theme_bw() + 
  theme(plot.title = 
          element_text(hjust = 0.5, 
                       size=12, 
                       face='bold'), 
        legend.position = "none")                #customize annotations
         
  
#plot density of log(betas' product)
weather_stats %>% 
  ggplot(aes(x = log_beta_prod, 
             fill = "green", 
             color = "green")) +                  #plot density of log_beta_prod
  geom_density(alpha = 0.3) +
  labs(title = "Density plot of log(β̂0xβ̂1) across 5000 straps",
       y = "Density (%)",
       x = "log(β̂0xβ̂1") +                           #add graph and axis title
  theme_bw() + 
  theme(plot.title = 
          element_text(hjust = 0.5, 
                       size=12, 
                       face='bold'), 
        legend.position = "none")  
```

We can get 95% CI for R-squared and log(β̂0xβ̂1)
```{r}
weather_stats %>% pull(r.squared) %>% as.vector() %>% quantile(c(0.25, 0.975))

weather_stats %>% pull(log_beta_prod) %>% as.vector() %>% quantile(c(0.25, 0.975))
```